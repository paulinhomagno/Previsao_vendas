{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abbd3c44",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff420f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, date, timedelta\n",
    "\n",
    "import inflection\n",
    "import math\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import Image\n",
    "\n",
    "from scipy import stats\n",
    "from pycorrcat.pycorrcat import corr_matrix\n",
    "\n",
    "from boruta import BorutaPy\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, RANSACRegressor, Lasso\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "\n",
    "import optuna\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "#sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a8819d",
   "metadata": {},
   "source": [
    "# Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab504aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# função padroniza a exibição dos gráficos\n",
    "def jupyter_settings():\n",
    "    %matplotlib inline\n",
    "\n",
    "    plt.style.use( 'bmh' )\n",
    "    plt.rcParams['figure.figsize'] = [20, 10]\n",
    "    plt.rcParams['font.size'] = 24\n",
    "\n",
    "    display( HTML( '<style>.container { width:100% !important; }</style>') )\n",
    "    pd.options.display.max_columns = None\n",
    "    pd.options.display.max_rows = None\n",
    "    pd.set_option( 'display.expand_frame_repr', False )\n",
    "\n",
    "    sns.set()\n",
    "    \n",
    "jupyter_settings()\n",
    "\n",
    "\n",
    "# função que calcula e retorna a correlação de Cramer's V\n",
    "def cramer_v(x , y):\n",
    "    \n",
    "    tabela = pd.crosstab(x, y).values\n",
    "    n = tabela.sum()\n",
    "    r,k = tabela.shape\n",
    "    \n",
    "    kcorr = k - ((k-1)**2 / (n-1 ))\n",
    "    rcorr = r - ((r-1)**2 / (n-1 ))\n",
    "    \n",
    "    chi2 = stats.chi2_contingency(tabela)[0]\n",
    "    chi2corr = max(0, chi2 - ( (k-1) * (r-1) / (n-1) ))\n",
    "    \n",
    "    return np.sqrt((chi2corr / n) / ( min(kcorr-1, rcorr-1) ))\n",
    "\n",
    "\n",
    "# função que calcula e retorna as métricas do modelo preditivo\n",
    "def ml_error(model, y, yhat):\n",
    "    \n",
    "    mae = mean_absolute_error(y, yhat)\n",
    "    mape = mean_absolute_percentage_error(y, yhat)\n",
    "    rmse = np.sqrt(mean_squared_error(y, yhat))\n",
    "    \n",
    "    return pd.DataFrame({'Modelo': model,\n",
    "                       'MAE': mae,\n",
    "                        'MAPE': mape,\n",
    "                        'RMSE': rmse}, index = [0])\n",
    "\n",
    "\n",
    "# função de modelagem preditiva com cross-validation aplicada a time series\n",
    "def cross_validation_timeseries(name, model, split, data, opt = False):\n",
    "    \n",
    "    tscv = TimeSeriesSplit(n_splits = split)\n",
    "    evaluation = pd.DataFrame()\n",
    "    \n",
    "    for train_index, test_index in tscv.split(data):\n",
    "        \n",
    "        # split treino e teste\n",
    "        cv_train, cv_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        \n",
    "        #modelo\n",
    "        cv_model = model.fit(cv_train.drop(['sales', 'date'], axis = 1), cv_train['sales'])\n",
    "\n",
    "        # predição\n",
    "        prediction = cv_model.predict(cv_test.drop(['sales', 'date'], axis = 1))\n",
    "        \n",
    "\n",
    "        # concatena os resultados a casa iteração\n",
    "        results = ml_error('CV Linear', np.expm1(cv_test['sales']), np.expm1(prediction))\n",
    "        evaluation = pd.concat([evaluation, results])\n",
    "        \n",
    "    if opt:\n",
    "\n",
    "        return - evaluation['RMSE'].mean()\n",
    "\n",
    "    else:  \n",
    "            # retorna a média e desvio padrão dos resultados    \n",
    "        return pd.DataFrame({'Modelo': name,\n",
    "                           'MAE': round(evaluation['MAE'].mean(),2).astype(str) + ' +/- ' + round(evaluation['MAE'].std(),2).astype(str),\n",
    "                            'MAPE': round(evaluation['MAPE'].mean(),2).astype(str) + ' +/- ' + round(evaluation['MAPE'].std(),2).astype(str),\n",
    "                            'RMSE': round(evaluation['RMSE'].mean(),2).astype(str) + ' +/- ' + round(evaluation['RMSE'].std(),2).astype(str)}, \n",
    "                            index = [0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca427680",
   "metadata": {},
   "source": [
    "# Descrição dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc60c1e8",
   "metadata": {},
   "source": [
    "Nesta seção, realizamos uma análise inicial dos dados com o objetivo de entender sua natureza e realizar alguns tratamentos necessários. Através dessa análise, podemos criar hipóteses e posteriormente realizar uma análise exploratória melhor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756df5f4",
   "metadata": {},
   "source": [
    "## Carregando os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ebfc57",
   "metadata": {},
   "source": [
    "Importando os dados de treino com dados de venda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd69cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales = pd.read_csv('data/train.csv', low_memory = False)\n",
    "df_sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3be43b",
   "metadata": {},
   "source": [
    "Importando dados das lojas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfe3e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_store = pd.read_csv('data/store.csv', low_memory = False)\n",
    "df_store.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec98f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.merge(df_sales, df_store, how = 'left', on = 'Store')\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3736ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcbaae94",
   "metadata": {},
   "source": [
    "## Renomeando Colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1ba4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797be399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usando a função underscore do módulo inflection deixando todas as primeiras letras das palavas em minúsculo\n",
    "cols_pre = ['Store', 'DayOfWeek', 'Date', 'Sales', 'Customers', 'Open', 'Promo',\n",
    "            'StateHoliday', 'SchoolHoliday', 'StoreType', 'Assortment',\n",
    "            'CompetitionDistance', 'CompetitionOpenSinceMonth',\n",
    "            'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek','Promo2SinceYear', 'PromoInterval'] \n",
    "\n",
    "snakecase = lambda x: inflection.underscore(x) \n",
    "\n",
    "cols_new = list(map(snakecase, cols_pre))\n",
    "df1.columns = cols_new\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d4cb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21ce289",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74fada3",
   "metadata": {},
   "source": [
    "Transformando a coluna date em formato de data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb16512",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['date'] = pd.to_datetime(df1['date'])\n",
    "df1['date'].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7238b9d",
   "metadata": {},
   "source": [
    "## Tratamento Valores Nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b8ae33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7e39e3",
   "metadata": {},
   "source": [
    "A variável competition_distance representa a distância da loja concorrente mais próxima. Vamos considerar que as lojas com valores nulos não têm concorrentes próximos ou estão muito distantes para serem considerados competidores. Para preencher esses valores nulos, usaremos um número bem acima do maior valor encontrado nesta coluna. Será colocado o dobro do maior valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9619d0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#competition_distance  \n",
    "max_value = df1['competition_distance'].max()\n",
    "\n",
    "df1['competition_distance'] = df1['competition_distance'].apply(lambda x: 2*(max_value) if math.isnan(x) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ffe6ec",
   "metadata": {},
   "source": [
    "As variáveis competition_open_since_month e competition_open_since_year são as datas de abertura da loja concorrente, alguns valores nulos podem corresponder a ausência de concorrente próximo, mas, como há um valor elevado ausentes, podem não haver este registro. Mas, para manter esta variável e verificar sua importância no modelo os valores nulos serão preenchidos com a mesma data da coluna 'date' na respectiva linha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d816d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#competition_open_since_month    \n",
    "df1['competition_open_since_month'] = list(map(lambda x: x[0].month if math.isnan(x[1]) else x[1], \n",
    "                                         df1[['date', 'competition_open_since_month']].values))\n",
    "\n",
    "\n",
    "#competition_open_since_year     \n",
    "df1['competition_open_since_year'] = list(map(lambda x: x[0].year if math.isnan(x[1]) else x[1], \n",
    "                                         df1[['date', 'competition_open_since_year']].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f1eaa4",
   "metadata": {},
   "source": [
    "As variáveis Promo2_since_week e Promo2_since_year  descrevem a semana/ano em que a loja participou da promo2. Promo2 representa se a loja participou da continuação da promoção. Verificando os casos nulos estes representam que a loja não participou. Então, semelhante aos casos anteriores, estas linhas serão preenchidas com a semana/ano com base na coluna 'date'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a9abc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#promo2_since_week               \n",
    "df1['promo2_since_week'] = list(map(lambda x: x[0].week if math.isnan(x[1]) else x[1], \n",
    "                            df1[['date', 'promo2_since_week']].values))\n",
    "\n",
    "#promo2_since_year               \n",
    "df1['promo2_since_year'] = list(map(lambda x: x[0].year if math.isnan(x[1]) else x[1], \n",
    "                            df1[['date', 'promo2_since_year']].values))\n",
    "             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71579ce6",
   "metadata": {},
   "source": [
    "A variavel promo_interval descreve os meses em que a promo2 ficou ativa. Os valores nulos serão preenchidos com 0 e será criada uma outra variável que observará se a data (date) foi está no período da promo_interval, indicando uma compra na promoção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9159779f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#promo_interval \n",
    "df1['promo_interval'].fillna(0, inplace = True)\n",
    "\n",
    "# criando uma variável com o mês de date\n",
    "df1['month_date'] = df1.apply(lambda x: x['date'].strftime('%b'), axis = 1)\n",
    "\n",
    "df1['is_promo'] = list(map(lambda x: 1 if (x[1] !=0) and (x[0] in x[1]) else 0, \n",
    "                            df1[['month_date', 'promo_interval']].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334ad0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc55cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['competition_open_since_month'] = df1['competition_open_since_month'].astype(int)\n",
    "df1['competition_open_since_year'] = df1['competition_open_since_year'].astype(int)\n",
    "df1['promo2_since_week'] = df1['promo2_since_week'].astype(int)\n",
    "df1['promo2_since_year'] = df1['promo2_since_year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0256cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867e57f0",
   "metadata": {},
   "source": [
    "## Análise descritiva"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63aaf5b0",
   "metadata": {},
   "source": [
    "### Variáveis Númericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6835b9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attributes = df1.select_dtypes('number')\n",
    "\n",
    "num_attributes.agg([\"mean\",\"median\",\"std\",\"min\",\"max\",\n",
    "                    \"skew\",\"kurtosis\"]).T.reset_index().rename(columns={'index': 'columns'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41443262",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df1['sales'], kde = True, bins = 50);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09686550",
   "metadata": {},
   "source": [
    "A variável resposta (sales) apresenta muitos valores zero (0), que são os dias em que a loja não abriu, trataremos isto no feature engineering.  \n",
    "As variáveis de ano, mês e semana transformaremos em uma única variável data e da variável date construiremos outras variáveis para extrair informações e testar hipóteses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b25e167",
   "metadata": {},
   "source": [
    "### Variáveis Categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5626b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_attributes = df1.select_dtypes('object')\n",
    "cat_attributes.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c46c1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aux = df1[(df1['sales'] > 0)]\n",
    "plt.subplots(figsize = (10,4))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "sns.boxplot(x= 'state_holiday', y = 'sales', data = df_aux);\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "sns.boxplot(x= 'store_type', y = 'sales', data = df_aux);\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "sns.boxplot(x= 'assortment', y = 'sales', data = df_aux);\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88116c42",
   "metadata": {},
   "source": [
    "Transformaremos algumas destas variáveis no feature engineering inserindo seus rótulos correspondentes para melhor análise exploratória."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432380ac",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41a03dc",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Nesta etapa, são realizadas as transformações e criações de variáveis com base na descrição inicial dos dados e no mapa mental de hipóteses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5ad481",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Mapa mental de Hipóteses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58e8198",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Image('images/mindmap.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4ca364",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Criação das Hipóteses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d37bc22",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Hipóteses criadas a partir do mapa mental."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4617a92c",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Loja"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5147b51a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "***1 -*** Lojas com mais funcionários vendem mais  \n",
    "***2 -*** Lojas com maior estoque vende mais  \n",
    "***3 -*** Lojas com maior porte vendem mais  \n",
    "***4 -*** Lojas com maior variedade de produtos vendem mais  \n",
    "***5 -*** Lojas com competidores mais próximos vendem menos  \n",
    "***6 -*** Lojas com competidores há mais tempo vendem mais  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef536174",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Produto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386ac15a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "***1 -*** Lojas que investem mais em marketing vendem mais  \n",
    "***2 -*** Lojas que expõe mais os produtos nas vitrines vendem mais  \n",
    "***3 -*** Lojas com preços menores nos produtos vendem mais  \n",
    "***4 -*** Lojas com promoções maiores vendem mais  \n",
    "***5 -*** Lojas com promoções ativas por mais tempo vendem mais  \n",
    "***6 -*** Lojas com mais promoções consecutivas vendem mais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d14920",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Tempo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01020d27",
   "metadata": {
    "hidden": true
   },
   "source": [
    "***1 -*** Lojas com mais feriados vendem menos   \n",
    "***2 -*** Lojas vende mais no Natal    \n",
    "***3 -*** Lojas vendem mais ao longo dos anos  \n",
    "***4 -*** Lojas vendem mais no ssegundo semestre  \n",
    "***5 -*** Lojas vendem menos nos finais de semana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e3b2e4",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Lista Final Hipóteses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51176411",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Hipóteses filtradas a partir dos dados existentes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521f3fc6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* Lojas com maior variedade de produtos vendem mais    \n",
    "* Lojas com competidores mais próximos vendem menos  \n",
    "* Lojas com competidores há mais tempo vendem mais  \n",
    "* Lojas com promoções ativas por mais tempo vendem mais  \n",
    "* Lojas com mais promoções consecutivas vendem mais\n",
    "* Lojas com mais feriados vendem menos   \n",
    "* Lojas vende mais no Natal\n",
    "* Lojas vendem mais ao longo dos anos  \n",
    "* Lojas vendem mais no segundo semestre  \n",
    "* Lojas vendem menos nos finais de semana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0a71e2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34749eac",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Extraindo os tempos necessários da variável date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87e3500",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df2['year'] = df2['date'].dt.year\n",
    "df2['month'] = df2['date'].dt.month\n",
    "df2['day'] = df2['date'].dt.day\n",
    "df2['week_year'] = df2['date'].dt.isocalendar().week\n",
    "df2['year_and_week'] = df2['date'].dt.strftime('%Y-%W')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0415c93e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Criando variáveis para contagem de tempo de competição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79790b71",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df2['competition_since'] = list(map(lambda x : datetime(year = x[0], \n",
    "                        month = x[1], day = 1), \n",
    "                        df2[['competition_open_since_year', 'competition_open_since_month']].values))\n",
    "\n",
    "df2['competition_time_month'] = ((df2['date'] - df2['competition_since']) / 30).apply(lambda x: x.days)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3855c57",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Criando variáveis para contagem de tempo de promoção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d626218a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df2['promo_since'] = df2['promo2_since_year'].astype(str) + '-'+ df2['promo2_since_week'].astype(str)\n",
    "df2['promo_since'] = list(map(lambda x: datetime.strptime(x + '-1', '%Y-%W-%w') - timedelta(days = 7), \n",
    "                df2['promo_since']))\n",
    "\n",
    "df2['promo_time_week'] = ((df2['date'] - df2['promo_since']) / 7).apply(lambda x: x.days)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ac3c5b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Colocando rótulos para variáveis categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fb6803",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#assortiment\n",
    "df2['assortment_label'] = df2['assortment'].apply(lambda x: 'basic' if x == 'a' else 'extra' if x == 'b' else 'extend')\n",
    "\n",
    "#state_holiday\n",
    "df2['state_holiday'] = df2['state_holiday'].apply(lambda x: 'public_holiday' if x == 'a' \n",
    "                        else 'easter_holiday' if x == 'b' else 'christmas' if x == 'c' else 'regular_day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e4bc15",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df2.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530f8e28",
   "metadata": {},
   "source": [
    "# Filtragem Variáveis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d898037",
   "metadata": {},
   "source": [
    "Com base em regras de negócio e restrições específicas, algumas linhas e variáveis serão removidas.  \n",
    "A variável 'customers' não estará disponível para previsões com novos dados e, portanto, será excluída.   \n",
    "Além disso, lojas fechadas não realizam vendas, então essas linhas serão removidas, assim como as vendas com valor zero.  \n",
    "Também serão excluídas algumas colunas que foram transformadas no Feature Engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f2d268",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188d6f0a",
   "metadata": {},
   "source": [
    "## Filtragem de linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5023a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3[(df3['open'] != 0) & (df3['sales'] > 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cceb20",
   "metadata": {},
   "source": [
    "## Seleção de colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e35d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_drop = ['customers', 'open', 'promo_interval', 'month_date']\n",
    "df3 = df3.drop(cols_drop, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525580c6",
   "metadata": {},
   "source": [
    "# Análise Exploratória de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e126e233",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bffdc0",
   "metadata": {},
   "source": [
    "## Análise Univariada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f6f29d",
   "metadata": {},
   "source": [
    "### Variável resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02802598",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df4['sales'], kde = True, bins = 50);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1313c1ac",
   "metadata": {},
   "source": [
    "A variável sale apresenta uma distribuição com assimetria a esquerda, os valores se acumulam nos valores menores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55ba9c9",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Variáveis Numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea3daa0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_attributes = df4.select_dtypes('number')\n",
    "num_attributes.hist(bins = 25);\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafd47de",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As vendas durante a semana são constantes, apenas domingo (dia 7 da semana) é bem pouco devido a ser raro as lojas abrirem.  \n",
    "A maioria das lojas possuem competidores próximos.  \n",
    "Os competidores abrem mais lojas nos meses 9 e 4.  \n",
    "As lojas tiveram mais competidores no último ano.  \n",
    "Há maior quantidade de vendas quando não tem promoção.  \n",
    "Há maior quantidade de vendas nos primeiros 7 meses, nos últimos meses tem constancia menor de vendas.  \n",
    "Houve um pico de vendas nas promoçoes de 2013 e após constante queda até 2015."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9146b76",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Variáveis categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91536d0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df4.select_dtypes('object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4c878b",
   "metadata": {
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "holiday = df4[(df4['state_holiday'] != 'regular_day')]\n",
    "\n",
    "plt.subplot(221)\n",
    "sns.countplot(x = holiday['state_holiday']);\n",
    "\n",
    "# plt.subplot(322)\n",
    "# sns.kdeplot(data = holiday, x = 'sales', hue = 'state_holiday', fill = True)\n",
    "# plt.title('Sales holiday');\n",
    "\n",
    "plt.subplot(222)\n",
    "sns.countplot(x = df4['store_type']);\n",
    "\n",
    "# plt.subplot(324)\n",
    "# sns.kdeplot(data = df4, x = 'sales', hue = 'store_type', fill = True)\n",
    "# plt.title('Sales store type')\n",
    "\n",
    "plt.subplot(223)\n",
    "sns.countplot(x = df4['assortment_label']);\n",
    "\n",
    "# plt.subplot(326)\n",
    "# sns.kdeplot(data = df4, x = 'sales', hue = 'assortment_label', fill = True);\n",
    "# plt.title('Sales assortment');\n",
    "# plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dad53a8",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "## Análise Bivariada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3debc024",
   "metadata": {},
   "source": [
    "Análise das variáveis buscando validar as hipóteses anteriormente criadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254f01ae",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### H1. Lojas com maior variedade de produtos vendem mais.\n",
    "_**Não validada, lojas com maior variedade(assortment) vendem menos.**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423c89b3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['sales', 'assortment_label']].groupby('assortment_label').sum().reset_index()\n",
    "\n",
    "plt.subplot(121)\n",
    "sns.barplot(x = 'assortment_label', y = 'sales', data = aux1);\n",
    "\n",
    "plt.subplot(122)\n",
    "sns.kdeplot(data = df4, x = 'sales', hue = 'assortment_label', fill = True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb52b8f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aux2 = df4[['year_and_week','sales', 'assortment_label']].groupby(['year_and_week','assortment_label']).sum().reset_index()\n",
    "aux2.pivot(index = 'year_and_week', columns = 'assortment_label', values = 'sales').plot();\n",
    "\n",
    "aux3 = aux2[aux2['assortment_label'] == 'extra']\n",
    "aux3.pivot(index = 'year_and_week', columns = 'assortment_label', values = 'sales').plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf68af0",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Considerando 'extra' como lojas de maior variedade/sortimento a hipótese nao é validada, este tipo de loja vende menos.  \n",
    "Basic e extends são semelhantes em vendas e se comportam igualmente ao longo do tempo. O grupo mais distinto e com poucas vendas é o 'extra', observando-o ao longo do tempo, a tendência não é linear como parece mostrar no primeiro gráfico. Parece haver uma sazonalidade onde se vende menos neste tipo de loja. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21df4d79",
   "metadata": {},
   "source": [
    "#### H2. Lojas com competidores mais próximos vendem menos.\n",
    "_**Não validada, lojas com competidores mais próximos vendem mais.**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99b47b6",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['sales', 'competition_distance']].groupby('competition_distance').sum().reset_index()\n",
    "\n",
    "plt.subplot(131)\n",
    "sns.scatterplot(x = 'competition_distance', y = 'sales', data = aux1);\n",
    "\n",
    "plt.subplot(132)\n",
    "\n",
    "bins = list(np.arange(0,20000,1000))\n",
    "aux1['binned_competition_distance'] = pd.cut(aux1['competition_distance'], bins = bins)\n",
    "aux2 = aux1[['sales', 'binned_competition_distance']].groupby('binned_competition_distance').sum().reset_index()\n",
    "\n",
    "sns.barplot(x = 'binned_competition_distance', y = 'sales', data = aux2);\n",
    "plt.xticks(rotation = 45);\n",
    "\n",
    "plt.subplot(133)\n",
    "sns.heatmap(aux1[['sales', 'competition_distance']].corr(method = 'pearson'), annot = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb9a93d",
   "metadata": {},
   "source": [
    "Os gráficos mostram o contrário da hipótese, lojas com competidores mais próximos tendem a vender mais, e a correlação mostra esta tendência decrescente. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b43259",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Lojas com competidores há mais tempo vendem mais.\n",
    "_**Não validada, lojas com competidores há mais tempo vendem menos.**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca123cd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['sales', 'competition_time_month']].groupby('competition_time_month').sum().reset_index()\n",
    "aux2 = aux1[(aux1['competition_time_month'] < 120) & (aux1['competition_time_month'] != 0)]\n",
    "\n",
    "plt.subplot(211)\n",
    "sns.barplot(x = 'competition_time_month', y = 'sales', data = aux2);\n",
    "plt.xticks(rotation = 90);\n",
    "\n",
    "plt.subplot(223)\n",
    "sns.regplot(x = 'competition_time_month', y = 'sales', data = aux2);\n",
    "\n",
    "plt.subplot(224)\n",
    "sns.heatmap(aux1.corr(method = 'pearson'), annot = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d2c6df",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Como comparamos a data da venda com a data de abertura do concorrente há valores negativos pois alguns competidores abriram loja depois da data de venda. Podemos observar que quanto mais próximo de 0, ou seja, mais recente a competição, maior são as vendas. A competição tem bastante impacto nas vendas, podemos notar uma tendência decrescente mas não é uma correlação linear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fd854a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Lojas com promoções ativas por mais tempo vendem mais .\n",
    "_**Não validada, lojas com promoções ativas tem uma regularidade de vendas durante um tempo, após, começa a declinar.**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6369973a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['promo_time_week', 'sales']].groupby('promo_time_week').sum().reset_index()\n",
    "aux2 = aux1[aux1['promo_time_week'] > 0] # tempo promoção extendida\n",
    " \n",
    "\n",
    "bins = list(np.arange(0,320,5))\n",
    "aux2['binned_promo_time'] = pd.cut(aux1['promo_time_week'], bins = bins)\n",
    "aux3 = aux2[['sales', 'binned_promo_time']].groupby('binned_promo_time').sum().reset_index()\n",
    "\n",
    "aux4 = aux1[aux1['promo_time_week'] < 0] # tempo promoção regular\n",
    "\n",
    "\n",
    "plt.subplot(221)\n",
    "sns.barplot(x = 'binned_promo_time', y = 'sales', data = aux3);\n",
    "plt.title('Promoção extendida', fontsize = 20)\n",
    "plt.xticks(rotation = 90);\n",
    "\n",
    "plt.subplot(222)\n",
    "sns.regplot(x = 'promo_time_week', y = 'sales', data = aux2);\n",
    "\n",
    "plt.subplot(223)\n",
    "sns.barplot(x = 'promo_time_week', y = 'sales', data = aux4);\n",
    "plt.title('Promoção regular', fontsize = 20)\n",
    "plt.xticks(rotation = 90);\n",
    "\n",
    "plt.subplot(224)\n",
    "sns.regplot(x = 'promo_time_week', y = 'sales', data = aux4);\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c335ce",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Na promoção estendida, percebe-se que há um período de efeito em que as vendas atingem um patamar e mantêm-se regulares, mas começa a declinar após a semana 225, o que gera uma reta com tendência negativa. Já na promoção regular, ocorrem saltos de vendas à medida que a promoção estendida se aproxima mostrando um tendência crescente. Portanto, a hipótese de que as vendas aumentam à medida que a promoção se estende não é validada, já que as vendas caem após um período de regularidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4983288a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,4))\n",
    "sns.heatmap(aux1.corr(method = 'pearson'), annot = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29463a6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Esta variável apresenta correlação negativa muito baixa, possivelmente afetada pelo período longo de constância na promoção, talvez não seja relevante para o modelo se não for combinada com outra(s) variável(is)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b322db4",
   "metadata": {},
   "source": [
    "#### Lojas com promoções consecutivas vendem mais.\n",
    "_**Não validada, lojas com promoção estendida venderam menos.**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127403fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4[['promo', 'promo2', 'sales']].groupby(['promo', 'promo2']).sum().reset_index().sort_values(by = 'sales', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e5a155",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux1 = df4[(df4['promo'] == 1) & (df4['promo2'] == 1)][['year_and_week', 'sales']].groupby('year_and_week').sum().reset_index()\n",
    "ax = aux1.plot();\n",
    "\n",
    "aux2 = df4[(df4['promo'] == 1) & (df4['promo2'] == 0)][['year_and_week', 'sales']].groupby('year_and_week').sum().reset_index()\n",
    "aux2.plot(ax =ax);\n",
    "\n",
    "ax.legend(labels = ['Tradicional & Estendida', 'Tradicional']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a7b9cd",
   "metadata": {},
   "source": [
    "Como se observa no gráfico a prorrogação da promoção não aumentam as vendas, contrariando a hipótese. E se percebe nas linhas do gráfico, que na maior parte o comportamento é o mesmo, possivelmente não será uma variável tão relevante para o modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0c2156",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Lojas vende mais no Natal\n",
    "_**Não validada, as lojas vendem menos no feriado de Natal.**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e268dcfb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[df4['state_holiday'] != 'regular_day']\n",
    "aux2 = aux1[['state_holiday', 'sales']].groupby('state_holiday').sum().reset_index()\n",
    "\n",
    "plt.subplot(121)\n",
    "sns.barplot(x = 'state_holiday', y = 'sales', data = aux2);\n",
    "\n",
    "plt.subplot(122)\n",
    "aux3 = aux1[['year', 'state_holiday', 'sales']].groupby(['year', 'state_holiday']).sum().reset_index()\n",
    "sns.barplot(x = 'year', y = 'sales', hue = 'state_holiday', data = aux3);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c6fe65",
   "metadata": {},
   "source": [
    "#### Lojas vendem mais ao longo dos anos  \n",
    "_**Não validada, as vendas estão com tendência de queda.**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045729d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4[['year', 'sales']].groupby('year').sum().plot(kind = 'bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938916b6",
   "metadata": {},
   "source": [
    "Apesar dos dados do último ano (2015) não estar completo, podemos verificar uma tendência de queda nas vendas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89e618d",
   "metadata": {},
   "source": [
    "#### Lojas vendem mais no segundo semestre  \n",
    "_**Não validada, as lojas vendem menos no segundo semestre.**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a054f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux1 = df4[['month', 'sales']].groupby('month').sum().reset_index()\n",
    "\n",
    "plt.subplot(121)\n",
    "sns.barplot(x = 'month', y = 'sales', data = aux1);\n",
    "\n",
    "plt.subplot(122)\n",
    "sns.regplot(x = 'month', y = 'sales', data = aux1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7c72a2",
   "metadata": {},
   "source": [
    "Nos gráficos, notamos o contrário da hipótese, nos primeiros 6 meses há mais vendas, e uma queda notável a partir do 7º mês."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421fa0db",
   "metadata": {},
   "source": [
    "#### Lojas vendem menos nos finais de semana\n",
    "_**Validada, as vendas caem nos finais de semana.**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eca6743",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux1 = df4[['day_of_week', 'sales']].groupby('day_of_week').sum().reset_index()\n",
    "\n",
    "plt.subplot(121)\n",
    "sns.barplot(x = 'day_of_week', y = 'sales', data = aux1);\n",
    "\n",
    "plt.subplot(122)\n",
    "sns.regplot(x = 'day_of_week', y = 'sales', data = aux1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d9b2ce",
   "metadata": {},
   "source": [
    "Os gráficos mostram queda nas vendas ao se aproximar dos fins de semana, assim, as vendas tendem a ser maiores em dias de semana."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b5554c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Análise Multivariada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adcf92f",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Variáveis númericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9b85d0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "corr_num = num_attributes.corr(method = 'pearson')\n",
    "sns.heatmap(corr_num, annot = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5bd4c1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31d4a0a4",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Variáveis categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2ff66a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Para verificar a associação entre as colunas categóricas vamos utilizar o coeficiente V de Cramer com correção (https://en.wikipedia.org/wiki/Cram%C3%A9r%27s_V), que pode ser aplicado em situações onde a informação se encontra distribuída por categorias nominais. O coeficiente tem valores entre 0 e 1, quanto mais próximo de 1 maior a correlação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25211106",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cat_attributes = df4.drop(['assortment', 'year_and_week'], axis =1).select_dtypes('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e07961c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rows= []\n",
    "\n",
    "for column in cat_attributes.columns:\n",
    "    col = []\n",
    "    \n",
    "    for column2 in cat_attributes.columns:\n",
    "        if column == column2:\n",
    "            cramer = 1.0\n",
    "        else:\n",
    "            cramer =  corr_matrix(cat_attributes,[column,column2]).values[0][1]\n",
    "        col.append(round(cramer, 4))\n",
    "        \n",
    "    rows.append(col)\n",
    "     \n",
    "cramer_results = np.array(rows)\n",
    "\n",
    "df_cramer = pd.DataFrame(cramer_results, columns = cat_attributes.columns, index =cat_attributes.columns)\n",
    "sns.heatmap(df_cramer,annot = True) ; "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f49fca",
   "metadata": {},
   "source": [
    "# Preparação dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e63c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df4.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf365874",
   "metadata": {},
   "source": [
    "## Rescaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aebaf47",
   "metadata": {},
   "source": [
    "As variáveis numéricas não possuem uma distribuição normal, então para transformar estes dados vamos utilizar técnicas de rescaling, Min-Max Scaler (Normalização) para variáveis que não são afetadas por outliers e o Robust Scaler para as que possuem outliers relevantes:  \n",
    "<center><b>Min-Max Scaler:</b></center></br>\n",
    "$$\n",
    "X_n = \\frac{X_i + X_min}{X_max - X_min)}\\\\ \\\\    \n",
    "$$</br>\n",
    "$$\n",
    "\\mu = média\\\\\n",
    "$$\n",
    "<center><b>Robust Scaler</b></center></br>\n",
    "$$\n",
    "X_n = \\frac{X_i + Q_1(X)}{Q_3(X) - Q_1(X)}\n",
    "$$ </br>\n",
    "$$\n",
    "Q_1(X) = 1º Quartil\\\\\n",
    "Q_3(X) = 3º Quartil\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29e2057",
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = RobustScaler()\n",
    "df5['competition_distance'] = rc.fit_transform(df5[['competition_distance']].values)\n",
    "df5['competition_time_month'] = rc.fit_transform(df5[['competition_time_month']].values)\n",
    "\n",
    "mms = MinMaxScaler()\n",
    "df5['promo_time_week'] = mms.fit_transform(df5[['promo_time_week']].values)\n",
    "df5['year'] = mms.fit_transform(df5[['year']].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0399df38",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Transformação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5befb57c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f938ac49",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# One Hot Enconding state_holiday\n",
    "ohe = OneHotEncoder(handle_unknown = 'ignore')\n",
    "ohe_state_holiday = ohe.fit_transform(df5[['state_holiday']].values.reshape(-1,1)).toarray()\n",
    "\n",
    "for i, column in enumerate(ohe.get_feature_names_out()):\n",
    "    df5[column] = ohe_state_holiday[:,i]\n",
    "    \n",
    "\n",
    "# Label Enconder\n",
    "le = LabelEncoder()\n",
    "df5['store_type'] = le.fit_transform(df5['store_type'])\n",
    "\n",
    "# Ordinal Encoder\n",
    "assortment_dict = {'basic': 1, 'extra': 2, 'extend': 3}\n",
    "df5['assortment'] = df5['assortment_label'].map(assortment_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daf6de4",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Transformação da variável resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47a1d39",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# transformação logarítma\n",
    "df5['sales'] = np.log1p(df5['sales'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b85269",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Transformação de Natureza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc83550",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As variáveis restantes são variáveis de tempo e que denotam um ciclo, para realizar as transformações vamos se basear no círculo trigonométrico, onde cada valor(dia da semana ou mês, por exemplo) será representada por duas novas features com as medidas de seno e outra cosseno, como explica a imagem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15114cc3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Image('images/ciclo_mes.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f622c867",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# month\n",
    "df5['month_sin'] = df5['month'].apply(lambda x: np.sin(x * (2. * np.pi/12 )))\n",
    "df5['month_cos'] = df5['month'].apply(lambda x: np.cos(x * (2. * np.pi/12 )))                                 \n",
    "                                      \n",
    "#day_of_week\n",
    "df5['day_of_week_sin'] = df5['day_of_week'].apply(lambda x: np.sin(x * (2. * np.pi/7 )))\n",
    "df5['day_of_week_cos'] = df5['day_of_week'].apply(lambda x: np.cos(x * (2. * np.pi/7 )))                                 \n",
    "\n",
    "#day\n",
    "df5['day_sin'] = df5['day'].apply(lambda x: np.sin(x * (2. * np.pi/30 )))\n",
    "df5['day_cos'] = df5['day'].apply(lambda x: np.cos(x * (2. * np.pi/30 )))\n",
    "\n",
    "#week_year\n",
    "df5['week_year_sin'] = df5['week_year'].apply(lambda x: np.sin(x * (2. * np.pi/52 )))\n",
    "df5['week_year_cos'] = df5['week_year'].apply(lambda x: np.cos(x * (2. * np.pi/52 )))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974d115c",
   "metadata": {},
   "source": [
    "# Seleção de variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803b90c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df5.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99958402",
   "metadata": {},
   "source": [
    "## Divisão treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf46455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b8c5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_drop = ['week_year', 'day', 'month', 'day_of_week', 'promo_since', \n",
    "             'competition_since', 'year_and_week', 'state_holiday', 'assortment_label']\n",
    "\n",
    "df6 = df6.drop(cols_drop, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97970ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021e1af5",
   "metadata": {},
   "source": [
    "Todas as lojas possuem a mesma data inicial e final de vendas neste dataset, como o modelo preditivo tem um objetivo temporal, vamos separar para o teste as últimas 6 semanas de venda. A última data de vendas é 2015-07-31 assim, a última data para treino será 2015-06-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e48f73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training dataset\n",
    "X_train = df6[df6['date'] < '2015-06-19']\n",
    "y_train = X_train['sales']\n",
    "\n",
    "# test dataset\n",
    "X_test = df6[df6['date'] >= '2015-06-19']\n",
    "y_test = X_test['sales']\n",
    "\n",
    "print('Treino:','\\n','shape: X-->',X_train.shape, 'y-->',y_train.shape)\n",
    "print('Data min:', X_train['date'].min())\n",
    "print('Data max:', X_train['date'].max(), '\\n')\n",
    "\n",
    "print('Teste:','\\n','shape: X-->',X_test.shape, 'y-->',y_test.shape)\n",
    "print('Data min:', X_test['date'].min())\n",
    "print('Data max:', X_test['date'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658b8b55",
   "metadata": {},
   "source": [
    "## Boruta para seleção de variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f99f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_n = X_train.drop(['date', 'sales'], axis = 1).values\n",
    "y_train_n = y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5827da9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_jobs = 1)\n",
    "\n",
    "boruta = BorutaPy(rf, n_estimators = 'auto', verbose = 2,random_state = 42).fit(X_train_n, y_train_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283cb9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols_sel = boruta.support_.tolist()\n",
    "cols_sel = [True,True,False, True, True, True, True, True, True, True, True, False, False, True,\n",
    " True, False, False, False, False, False, True, True, True, True, True, False, True]\n",
    "\n",
    "# melhores features\n",
    "cols_boruta = X_train.drop(['date', 'sales'], axis = 1).iloc[:,cols_sel].columns.to_list()\n",
    "\n",
    "\n",
    "# features não selecionadas\n",
    "cols_n_sel = list(np.setdiff1d(X_train.drop(['date', 'sales'], axis = 1).columns, cols_boruta))\n",
    "\n",
    "# colunas selecionadas\n",
    "cols_boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19f90bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colunas não selecionadas \n",
    "cols_n_sel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f995c380",
   "metadata": {},
   "source": [
    "Das features não selecionadas pelo Boruta vamos manter para o modelo as variáveis month_sin e week_year_sin, são variáveis cíclicas que pela intuição da análise exploratória e hipóteses podem ser relevantes, e,  as outras variáveis que complementam o 'ciclo' foram selecionadas pelo boruta(month_cos e week_year_cos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1bee3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_selected = ['store', 'promo', 'store_type', 'assortment', 'competition_distance', 'competition_open_since_month',\n",
    " 'competition_open_since_year', 'promo2', 'promo2_since_week', 'promo2_since_year', 'competition_time_month', 'promo_time_week', \n",
    "'month_cos', 'month_sin','day_of_week_sin', 'day_of_week_cos', 'day_sin', 'day_cos', 'week_year_cos', 'week_year_sin']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c7930a",
   "metadata": {},
   "source": [
    "# Modelos de machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893f2e8f",
   "metadata": {},
   "source": [
    "## Modelo Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6b41a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X_train[cols_selected]\n",
    "x_test = X_test[cols_selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbd960a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15197d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = x_test.copy()\n",
    "aux['sales'] = y_test.copy()\n",
    "\n",
    "aux1 = x_train.copy()\n",
    "aux1['sales'] = y_train.copy()\n",
    "\n",
    "# armazenando a media de vendas por loja da base de treino e atribuindoa predição a base de teste\n",
    "# predição\n",
    "aux2 = aux1[['sales', 'store']].groupby('store').mean().reset_index().rename(columns = {'sales': 'predict'})\n",
    "aux3 = pd.merge(aux, aux2, how = 'left', on = 'store')\n",
    "\n",
    "# performance\n",
    "model_baseline = ml_error('Average Model', np.expm1(aux['sales']), np.expm1(aux3['predict']))\n",
    "model_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cf2719",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbdf1a9",
   "metadata": {},
   "source": [
    "## Regressão Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd7939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelo\n",
    "lr = LinearRegression().fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# predição\n",
    "yhat_lr = lr.predict(x_test)\n",
    "\n",
    "# performance\n",
    "lr_result = ml_error('Regressão Linear', np.expm1(y_test), np.expm1(yhat_lr))\n",
    "lr_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85004b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_add = ['sales', 'date']\n",
    "cols_full = cols_selected + columns_add\n",
    "training = X_train[cols_full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143159af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "linear_cv = cross_validation_timeseries('Linear', model, 5, training )\n",
    "linear_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cde9d37",
   "metadata": {},
   "source": [
    "Este modelo apresenta erros maiores que o modelo base, o que pode ocorrer que os dados não apresentam um comportamento linear ou eventuais outliers estão impactando a performance do modelo. \n",
    "Então, analisaremos alguns modelos pensando nestas observações. Algoritmo RASAC modelar detectando e desconsiderando outliers e alguns algoritmos não lineares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f675b4",
   "metadata": {},
   "source": [
    "## Regressão Linear RANSAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf35bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelo\n",
    "lr_ransac = RANSACRegressor(loss = 'squared_error').fit(x_train, y_train)\n",
    "\n",
    "# predição\n",
    "yhat_ransac = lr_ransac.predict(x_test)\n",
    "\n",
    "# performance\n",
    "lr_ransac_result = ml_error('Regressão RANSAC', np.expm1(y_test), np.expm1(yhat_ransac))\n",
    "lr_ransac_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfd04f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando a quantidade de outliers detectados\n",
    "outliers = np.logical_not(lr_ransac.inlier_mask_)\n",
    "outliers.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc29c876",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RANSACRegressor(loss = 'squared_error')\n",
    "ransac_cv = cross_validation_timeseries('RANSAC', model, 5, training )\n",
    "ransac_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dcc21c",
   "metadata": {},
   "source": [
    "A retirada de muitas amostras (que foram entendidas pelo modelo como outliers) fez os erros aumentarem. Chegamos na conclusão até aqui que, os outliers não impactam na modelagem e os dados não possuem um comportamento mais complexo, não é linear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a4cf50",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8cfa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelo\n",
    "lr_rf = RandomForestRegressor(n_estimators = 50, n_jobs = -1, random_state = 30).fit(x_train, y_train)\n",
    "\n",
    "# predição\n",
    "yhat_rf = lr_rf.predict(x_test)\n",
    "\n",
    "# performance\n",
    "lr_rf_result = ml_error('Random Forest', np.expm1(y_test), np.expm1(yhat_rf))\n",
    "lr_rf_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fadc857",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators = 50, n_jobs = -1, random_state = 30)\n",
    "rf_cv = cross_validation_timeseries('Random Forest', model, 5, training )\n",
    "rf_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eeefad3",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835723bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelo\n",
    "lr_xgb = xgb.XGBRegressor(objective = 'reg:squarederror',\n",
    "                          n_estimators = 50,\n",
    "                          learning_rate = 0.1,\n",
    "                          max_depth = 10,\n",
    "                          colsample_bytree = 0.9).fit(x_train, y_train)\n",
    "\n",
    "# predição\n",
    "yhat_xgb = lr_xgb.predict(x_test)\n",
    "\n",
    "# performance\n",
    "lr_xgb_result = ml_error('XGBoost', np.expm1(y_test), np.expm1(yhat_xgb))\n",
    "lr_xgb_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c73633",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor(objective = 'reg:squarederror',\n",
    "                          n_estimators = 50,\n",
    "                          learning_rate = 0.1,\n",
    "                          max_depth = 10,\n",
    "                          colsample_bytree = 0.9)\n",
    "\n",
    "xgb_cv = cross_validation_timeseries('XGBoost', model, 5, training)\n",
    "xgb_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334cf6b0",
   "metadata": {},
   "source": [
    "## Comparação dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b7b6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelos simples\n",
    "models_result = pd.concat([model_baseline, lr_result, lr_ransac_result, lr_rf_result, lr_xgb_result])\n",
    "models_result.sort_values('RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5259e49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelos com cross validation\n",
    "models_result = pd.concat([linear_cv, ransac_cv, rf_cv, xgb_cv])\n",
    "models_result.sort_values('RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa48d57",
   "metadata": {},
   "source": [
    "O Random Forest obteve melhor performance, assim, vamos utilizá-lo para a próxima etapa, otimização dos hiperparâmetros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b753365",
   "metadata": {},
   "source": [
    "# Otimização dos hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cac4a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = n_estimators, \n",
    "max_features= max_features,\n",
    "max_depth = max_depth,\n",
    "min_samples_split = min_samples_split,\n",
    "min_samples_leaf = min_samples_leaf,\n",
    "bootstrap = bootstrap,\n",
    "n_jobs = -1, random_state = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b351fcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': [100,500],\n",
    "         \n",
    "          'max_depth':[5,20],\n",
    "          'min_samples_split': [2,10],\n",
    "          'min_samples_leaf': [1,5], \n",
    "}\n",
    "#'max_features': ['auto', 'sqrt'],\n",
    "#params = [(50,500),\n",
    " #         ('auto', 'sqrt'),\n",
    "  #        (5,20),\n",
    "   #       (2,5),\n",
    "    #      (1,5),\n",
    "     #     (True, False)]    \n",
    "\n",
    "\n",
    "def treina_modelo(setup):\n",
    "    \n",
    "    #n_estimators = params[0]\n",
    "    #max_features = params[1]\n",
    "    #max_depth = params[2]\n",
    "    #min_samples_split = params[3]\n",
    "    #min_samples_leaf = params[4]\n",
    "    #bootstrap =  params[5]  \n",
    "    \n",
    "    \n",
    "\n",
    "    model = RandomForestRegressor(setup)\n",
    "    \n",
    "    rmse_cv = cross_validation_timeseries('Random Forest', model, 5, training, True )\n",
    "    \n",
    "    return rmse_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8bd6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from bayes_opt import BayesianOptimization, UtilityFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cf499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results = BayesSearchCV(model, params, n_iter = 50, cv = 5, scoring = 'mean_absolute_error')\n",
    "\n",
    "#optimizer.maximize(ini_points = 5, n_inter = 10)\n",
    "\n",
    "util = UtilityFunction(kind='ucb',\n",
    "                                kappa=1.96,\n",
    "                                xi=0.001)\n",
    "\n",
    "def func_opt(n_estimators, max_features,max_depth,min_samples_split,min_samples_leaf):\n",
    "    \n",
    "    params_model = {}\n",
    "    params_model['n_estimators'] = int(n_estimators)\n",
    "    params_model['max_depth'] = int(max_depth)\n",
    "    params_model['min_samples_split'] = int(min_samples_split)\n",
    "    params_model['min_samples_leaf'] = int(min_samples_leaf)\n",
    "       \n",
    "    model = RandomForestRegressor(n_jobs = -1, random_state = 30, **params_model)\n",
    "    \n",
    "    rmse = cross_validation_timeseries('Random Forest', model, 5, training, True )\n",
    "    \n",
    "    return -rmse\n",
    "\n",
    "optimizer = BayesianOptimization(f = func_opt, pbounds = params, verbose = 1, random_state = 30 )\n",
    "optimizer.maximize(ini_points = 20, n_inter = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dd65b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt.util import Colours\n",
    "\n",
    "\n",
    "def rfc_cv(n_estimators, max_features,max_depth,min_samples_split,min_samples_leaf, training):\n",
    "    \n",
    "    estimator = RandomForestRegressor(\n",
    "        n_estimators=int(n_estimators),\n",
    "        max_features =max_features,\n",
    "        max_depth = max_depth,\n",
    "        min_samples_split = int(min_samples_split),\n",
    "        min_samples_leaf = int(min_samples_leaf),\n",
    "        random_state=30\n",
    "    )\n",
    "    \n",
    "    rmse = cross_validation_timeseries('Random Forest', estimator, 5, training, True )\n",
    "    \n",
    "    return -rmse\n",
    "\n",
    "\n",
    "def optimize_rfc(training):\n",
    "    \n",
    "    def rfc_crossval(n_estimators, max_features,max_depth,min_samples_split,min_samples_leaf):\n",
    "       \n",
    "        return rfc_cv(\n",
    "            n_estimators=int(n_estimators),\n",
    "            max_features=max(min(max_features, 0.999), 1e-3),\n",
    "            max_depth = int(max_depth),\n",
    "            min_samples_split = int(min_samples_split),\n",
    "            min_samples_leaf = min_samples_leaf,\n",
    "            training=training\n",
    "        )\n",
    "\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=rfc_crossval,\n",
    "        pbounds={\n",
    "           'n_estimators': (100,500),\n",
    "          \"max_features\": (0.1, 0.999),\n",
    "            'max_depth':(5,20),\n",
    "          'min_samples_split': (2,10),\n",
    "          'min_samples_leaf': (1,5) \n",
    "            },\n",
    "        random_state=30,\n",
    "        verbose=1\n",
    "    )\n",
    "    optimizer.maximize(n_iter=10)\n",
    "\n",
    "    print(\"Final result:\", optimizer.max)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(Colours.green(\"--- Optimizing Random Forest ---\"))\n",
    "    optimize_rfc(training)\n",
    "# aquiiiiiiiiiiiiiiiii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b710003",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = RandomForestRegressor(\n",
    "        n_estimators=485,\n",
    "        max_features = 'sqrt',\n",
    "        max_depth = 15,\n",
    "        min_samples_split = 3,\n",
    "        min_samples_leaf = 4,\n",
    "        random_state=30)\n",
    "\n",
    "estimator_ = cross_validation_timeseries('RFR', estimator, 5, training)\n",
    "estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1788b256",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
